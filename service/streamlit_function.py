from service.function import parse_song_form, render_song
from pptx import Presentation
from bs4 import BeautifulSoup
from urllib.parse import quote

import re
import streamlit as st
import requests
import pyperclip


def load_css(path: str):
    with open(path) as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)


def reset_session():
    st.session_state.part_count = 3
    st.session_state.reset_counter += 1

    st.session_state.pop("extracted_text", None)

    st.toast("ëª¨ë“  ì…ë ¥ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤", icon="ğŸ”„")
    st.rerun()


def collect_parts_from_session() -> dict[str, str]:
    """
    session_stateì— ì €ì¥ëœ íŒŒíŠ¸ëª…/ê°€ì‚¬ë¥¼ ì½ì–´ì„œ
    { "A": "ê°€ì‚¬", "B": "ê°€ì‚¬" } í˜•íƒœë¡œ ë°˜í™˜
    """
    parts: dict[str, str] = {}

    reset_counter = st.session_state.get("reset_counter", 0)
    part_count = st.session_state.get("part_count", 0)

    for i in range(part_count):
        name = st.session_state.get(f"part_name_{i}_{reset_counter}", "").strip()

        lyrics = st.session_state.get(f"part_lyrics_{i}_{reset_counter}", "").strip()

        if name and lyrics:
            parts[name] = lyrics

    return parts


def export_holiday(song_form: str) -> str:
    parts = collect_parts_from_session()

    parsed = parse_song_form(song_form)
    output_lines = []

    for token in parsed:
        if token.startswith("(") and token.endswith(")"):
            continue

        if token in parts:
            output_lines.append(parts[token].strip())
            output_lines.append("")  # â† íŒŒíŠ¸ë§ˆë‹¤ ë¬´ì¡°ê±´ ì—”í„° í•œ ì¤„

    result = "\n".join(output_lines)
    result = re.sub(r"//+", "", result).strip()

    formatted = f"""{st.session_state.get("song_title", "")}

{result}
"""

    pyperclip.copy(formatted)

    st.session_state.extracted_text = formatted
    st.toast("ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤ âœ…", icon="ğŸ“‹")


def export_retreat(song_form: str):
    parts_dict = collect_parts_from_session()

    formatted = f"""{{
    "title": "{st.session_state.get("song_title", "")}",
    "parts": {{
"""

    for k, v in parts_dict.items():
        indented_v = indent_text(v, spaces=18)

        formatted += f'''        "{k}": """
{indented_v}
""",
'''

    formatted += f"""    }},
    "song_form": "{song_form}",
}},
"""

    pyperclip.copy(formatted)
    st.session_state.extracted_text = formatted
    st.toast("ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤ âœ…", icon="ğŸ“‹")


def indent_text(text: str, spaces: int = 8) -> str:
    indent = " " * spaces
    return "\n".join(
        indent + line if line.strip() else line for line in text.splitlines()
    )


def ppt_save(list, path):
    prs = Presentation()

    for song in list:
        render_song(prs, song)

    prs.save(path)


def crawl_lyrics(song_name: str, limit: int = 8):
    url = f"https://music.bugs.co.kr/search/lyrics?q={quote(song_name)}"
    headers = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"}

    res = requests.get(url, headers=headers, timeout=10)
    res.raise_for_status()
    soup = BeautifulSoup(res.text, "html.parser")

    results = []

    rows = soup.select('tr[rowtype="lyrics"]')

    print(rows)

    for row in rows:
        if len(results) >= limit:
            break

        # track_id (ì§„ì§œ ê³¡ ID)
        track_id = row.get("trackid", "").strip()

        # ì œëª©
        title_a = row.select_one("a[title]")
        title = title_a.get_text(" ", strip=True) if title_a else ""

        # ì•„í‹°ìŠ¤íŠ¸
        artist_a = row.select_one('a[href*="/artist/"]')
        artist = artist_a.get_text(" ", strip=True) if artist_a else ""

        if track_id and title:
            results.append(
                {
                    "track_id": track_id,
                    "title": title,
                    "artist": artist,
                }
            )
    return results


def crawl_track_lyrics(track_id: str) -> str:
    url = f"https://music.bugs.co.kr/track/{track_id}"
    headers = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)"}

    res = requests.get(url, headers=headers, timeout=10)
    res.raise_for_status()

    soup = BeautifulSoup(res.text, "html.parser")

    # div.lyricsContainer ì•ˆì— xmpì— ê°€ì‚¬ê°€ ë“¤ì–´ìˆëŠ” êµ¬ì¡°
    xmp = soup.select_one("div.lyricsContainer xmp")
    if not xmp:
        return ""

    lyrics = xmp.get_text("\n", strip=True)
    return lyrics


def sync_lyrics_with_track():
    """
    track_id ë³€ê²½ì„ ê°ì§€í•´ì„œ
    í•´ë‹¹ ê³¡ì˜ ê°€ì‚¬ë¥¼ ì„¸ì…˜ì— ë™ê¸°í™”í•œë‹¤.
    """

    current_track_id = st.session_state.get("track_id")
    prev_track_id = st.session_state.get("prev_track_id")

    if current_track_id and current_track_id != prev_track_id:
        try:
            st.session_state.lyrics_text = crawl_track_lyrics(current_track_id)
            st.session_state.prev_track_id = current_track_id
        except Exception as e:
            st.toast(f"ê°€ì‚¬ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}", icon="âŒ")


def listup_lyrics_result(results):
    if not results:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤. (ìƒìœ„ 8ê°œë§Œ í‘œì‹œ)")
    else:
        for idx, r in enumerate(results):
            st.markdown(
                f"""
                <div class="song-card-wrapper">
                    <div class="song-card">
                        <div class="song-title">{r["title"]}</div>
                        <div class="song-artist">{r["artist"]}</div>
                    </div>
                </div>
                """,
                unsafe_allow_html=True,
            )

            if st.button(
                "select",
                key=f"search_select_{idx}",
                use_container_width=True,
            ):
                st.session_state.song_title = r["title"]
                st.session_state.song_artist = r["artist"]
                st.session_state.track_id = r["track_id"]
                st.rerun()
